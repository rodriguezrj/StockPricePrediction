{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XULRz8YjnP2a",
        "outputId": "a7767f7b-1f1a-4411-dca2-7398d04968cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  3 of 3 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of NaN values in each column:\n",
            " Ticker\n",
            "AAPL     0\n",
            "GOOGL    0\n",
            "MSFT     0\n",
            "dtype: int64\n",
            "Rows with NaN values:\n",
            " Empty DataFrame\n",
            "Columns: [AAPL, GOOGL, MSFT]\n",
            "Index: []\n",
            "Data after filling missing values:\n",
            " Ticker          AAPL      GOOGL       MSFT\n",
            "Date                                      \n",
            "2010-01-04  7.643214  15.684434  30.950001\n",
            "2010-01-05  7.656429  15.615365  30.959999\n",
            "2010-01-06  7.534643  15.221722  30.770000\n",
            "2010-01-07  7.520714  14.867367  30.450001\n",
            "2010-01-08  7.570714  15.065566  30.660000\n",
            "2010-01-11  7.503929  15.042793  30.270000\n",
            "2010-01-12  7.418571  14.776777  30.070000\n",
            "2010-01-13  7.523214  14.691942  30.350000\n",
            "2010-01-14  7.479643  14.761011  30.959999\n",
            "2010-01-15  7.354643  14.514515  30.860001\n",
            "2010-01-19  7.680000  14.705205  31.100000\n",
            "2010-01-20  7.561786  14.524775  30.590000\n",
            "2010-01-21  7.431071  14.589089  30.010000\n",
            "2010-01-22  7.062500  13.764014  28.959999\n",
            "2010-01-25  7.252500  13.513514  29.320000\n",
            "2010-01-26  7.355000  13.574074  29.500000\n",
            "2010-01-27  7.424286  13.566066  29.670000\n",
            "2010-01-28  7.117500  13.370621  29.160000\n",
            "2010-01-29  6.859286  13.261762  28.180000\n",
            "2010-02-01  6.954643  13.338839  28.410000\n",
            "2010-02-02  6.995000  13.291291  28.459999\n",
            "2010-02-03  7.115357  13.534034  28.629999\n",
            "2010-02-04  6.858929  13.182683  27.840000\n",
            "2010-02-05  6.980714  13.295546  28.020000\n",
            "2010-02-08  6.932857  13.350100  27.719999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download Historical Stock Data\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "\n",
        "# Define the stock tickers and download data\n",
        "tickers = ['AAPL', 'GOOGL', 'MSFT']\n",
        "data = yf.download(tickers, start='2010-01-01', end='2024-01-06')\n",
        "\n",
        "# Use the closing prices\n",
        "data = data['Close']\n",
        "\n",
        "# Check for NaN values in the dataset\n",
        "nan_counts = data.isna().sum()\n",
        "print(\"Number of NaN values in each column:\\n\", nan_counts)\n",
        "\n",
        "# Display rows with NaN values\n",
        "nan_rows = data[data.isna().any(axis=1)]\n",
        "print(\"Rows with NaN values:\\n\", nan_rows)\n",
        "\n",
        "# Fill missing values by backfilling\n",
        "data = data.bfill()\n",
        "print(\"Data after filling missing values:\\n\", data.head(25))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjqnTPn6nP2c",
        "outputId": "f7ed1fa2-a799-4e85-874b-cde816646a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with 50-day moving average:\n",
            " Ticker          AAPL      GOOGL       MSFT  AAPL_MA50  GOOGL_MA50  MSFT_MA50\n",
            "Date                                                                        \n",
            "2010-01-04  7.643214  15.684434  30.950001   7.391336   13.955175    29.1646\n",
            "2010-01-05  7.656429  15.615365  30.959999   7.391336   13.955175    29.1646\n",
            "2010-01-06  7.534643  15.221722  30.770000   7.391336   13.955175    29.1646\n",
            "2010-01-07  7.520714  14.867367  30.450001   7.391336   13.955175    29.1646\n",
            "2010-01-08  7.570714  15.065566  30.660000   7.391336   13.955175    29.1646\n",
            "2010-01-11  7.503929  15.042793  30.270000   7.391336   13.955175    29.1646\n",
            "2010-01-12  7.418571  14.776777  30.070000   7.391336   13.955175    29.1646\n",
            "2010-01-13  7.523214  14.691942  30.350000   7.391336   13.955175    29.1646\n",
            "2010-01-14  7.479643  14.761011  30.959999   7.391336   13.955175    29.1646\n",
            "2010-01-15  7.354643  14.514515  30.860001   7.391336   13.955175    29.1646\n",
            "2010-01-19  7.680000  14.705205  31.100000   7.391336   13.955175    29.1646\n",
            "2010-01-20  7.561786  14.524775  30.590000   7.391336   13.955175    29.1646\n",
            "2010-01-21  7.431071  14.589089  30.010000   7.391336   13.955175    29.1646\n",
            "2010-01-22  7.062500  13.764014  28.959999   7.391336   13.955175    29.1646\n",
            "2010-01-25  7.252500  13.513514  29.320000   7.391336   13.955175    29.1646\n",
            "2010-01-26  7.355000  13.574074  29.500000   7.391336   13.955175    29.1646\n",
            "2010-01-27  7.424286  13.566066  29.670000   7.391336   13.955175    29.1646\n",
            "2010-01-28  7.117500  13.370621  29.160000   7.391336   13.955175    29.1646\n",
            "2010-01-29  6.859286  13.261762  28.180000   7.391336   13.955175    29.1646\n",
            "2010-02-01  6.954643  13.338839  28.410000   7.391336   13.955175    29.1646\n",
            "2010-02-02  6.995000  13.291291  28.459999   7.391336   13.955175    29.1646\n",
            "2010-02-03  7.115357  13.534034  28.629999   7.391336   13.955175    29.1646\n",
            "2010-02-04  6.858929  13.182683  27.840000   7.391336   13.955175    29.1646\n",
            "2010-02-05  6.980714  13.295546  28.020000   7.391336   13.955175    29.1646\n",
            "2010-02-08  6.932857  13.350100  27.719999   7.391336   13.955175    29.1646\n"
          ]
        }
      ],
      "source": [
        "# Calculate the 50-day moving average for each stock\n",
        "data['AAPL_MA50'] = data['AAPL'].rolling(window=50).mean()\n",
        "data['GOOGL_MA50'] = data['GOOGL'].rolling(window=50).mean()\n",
        "data['MSFT_MA50'] = data['MSFT'].rolling(window=50).mean()\n",
        "\n",
        "# Fill NaN values created by rolling operation\n",
        "data = data.bfill()\n",
        "\n",
        "print(\"Data with 50-day moving average:\\n\", data.head(25))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgl8KgyznP2c",
        "outputId": "75a252d6-f52b-4944-e847-7aabd9138f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled data sample:\n",
            " [[0.00410081 0.03434761 0.02207456 0.         0.01562903 0.0134612 ]\n",
            " [0.00416991 0.03385045 0.02210236 0.         0.01562903 0.0134612 ]\n",
            " [0.00353313 0.03101697 0.02157413 0.         0.01562903 0.0134612 ]\n",
            " [0.00346029 0.02846629 0.02068448 0.         0.01562903 0.0134612 ]\n",
            " [0.00372173 0.02989295 0.02126831 0.         0.01562903 0.0134612 ]]\n"
          ]
        }
      ],
      "source": [
        "# Scale the Data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the scaler and fit to the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Scaled data sample:\\n\", data_scaled[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pax4YX9pnP2c",
        "outputId": "c6e2d696-c3e4-4cb2-871e-af1302c902e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split with ratio 0.8: train size = 2820, test size = 706\n",
            "Training data size for split 80.0-19.999999999999996: (2820, 6)\n",
            "Testing data size for split 80.0-19.999999999999996: (706, 6)\n"
          ]
        }
      ],
      "source": [
        "# Function to split data into training and testing sets\n",
        "def split_data(data, split_ratio=0.8):\n",
        "    train_size = int(len(data) * split_ratio)\n",
        "    train_data, test_data = data[:train_size], data[train_size:]\n",
        "    print(f\"Data split with ratio {split_ratio}: train size = {len(train_data)}, test size = {len(test_data)}\")\n",
        "    return train_data, test_data\n",
        "\n",
        "split_ratios = [0.8]\n",
        "datasets = [split_data(data_scaled, ratio) for ratio in split_ratios]\n",
        "\n",
        "for i, (train_data, test_data) in enumerate(datasets):\n",
        "    print(f\"Training data size for split {split_ratios[i]*100}-{(1-split_ratios[i])*100}: {train_data.shape}\")\n",
        "    print(f\"Testing data size for split {split_ratios[i]*100}-{(1-split_ratios[i])*100}: {test_data.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1tLZ-w7nP2d",
        "outputId": "5e26948d-0644-4b09-ff33-e37e47f3b48d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape for split 80.0-19.999999999999996: (2719, 100, 1)\n",
            "X_test shape for split 80.0-19.999999999999996: (605, 100, 1)\n"
          ]
        }
      ],
      "source": [
        "# Create Time-Series Data for LSTM\n",
        "def create_dataset(dataset, time_step=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - time_step - 1):\n",
        "        a = dataset[i:(i + time_step), 0]  # Create feature set\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + time_step, 0])  # Create label set\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "time_step = 100\n",
        "datasets_ts = [(create_dataset(train, time_step), create_dataset(test, time_step)) for train, test in datasets]\n",
        "\n",
        "for i, ((X_train, y_train), (X_test, y_test)) in enumerate(datasets_ts):\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "    print(f\"X_train shape for split {split_ratios[i]*100}-{(1-split_ratios[i])*100}: {X_train.shape}\")\n",
        "    print(f\"X_test shape for split {split_ratios[i]*100}-{(1-split_ratios[i])*100}: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY7sKD0gnP2d",
        "outputId": "f57227a6-909b-4caf-f703-900c995c3877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83BLn1uQnP2d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UmtYEYrnP2d",
        "outputId": "899b50e2-cb0d-4255-a7a0-f9f1e6ef78e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model with split 80.0-19.999999999999996 and params {'epochs': 2, 'batch_size': 1}...\n",
            "Epoch 1/2\n",
            "2719/2719 [==============================] - 40s 12ms/step - loss: 6.0756e-04 - val_loss: 0.0013\n",
            "Epoch 2/2\n",
            "2719/2719 [==============================] - 31s 11ms/step - loss: 3.0858e-04 - val_loss: 0.0011\n",
            "Training LSTM model with split 80.0-19.999999999999996 and params {'epochs': 2, 'batch_size': 32}...\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 6s 21ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 1.3007e-04 - val_loss: 0.0011\n"
          ]
        }
      ],
      "source": [
        "# Build and Train LSTM Model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "# Build and Train LSTM Model\n",
        "def build_and_train_lstm(X_train, y_train, X_test, y_test, epochs=10, batch_size=1):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
        "    return model, history\n",
        "\n",
        "hyperparams = [\n",
        "    {'epochs': 2, 'batch_size': 1},\n",
        "    {'epochs': 2, 'batch_size': 32}\n",
        "#   {'epochs': 5, 'batch_size': 1},\n",
        "#   {'epochs': 5, 'batch_size': 32}\n",
        "]\n",
        "\n",
        "lstm_results = []\n",
        "for i, ((X_train, y_train), (X_test, y_test)) in enumerate(datasets_ts):\n",
        "    for params in hyperparams:\n",
        "        print(f\"Training LSTM model with split {split_ratios[i]*100}-{(1-split_ratios[i])*100} and params {params}...\")\n",
        "        model, history = build_and_train_lstm(X_train, y_train, X_test, y_test, epochs=params['epochs'], batch_size=params['batch_size'])\n",
        "        lstm_results.append((model, history, f\"Split {split_ratios[i]*100}-{(1-split_ratios[i])*100}, Params {params}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWyBQLRWnP2d",
        "outputId": "b05f5dc5-9554-407f-e951-31647d5204b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GRU model with split 80.0-19.999999999999996 and params {'epochs': 2, 'batch_size': 1}...\n",
            "Epoch 1/2\n",
            "2719/2719 [==============================] - 36s 12ms/step - loss: 3.4003e-04 - val_loss: 2.9823e-04\n",
            "Epoch 2/2\n",
            "2719/2719 [==============================] - 30s 11ms/step - loss: 1.8310e-04 - val_loss: 3.1266e-04\n",
            "Training GRU model with split 80.0-19.999999999999996 and params {'epochs': 2, 'batch_size': 32}...\n",
            "Epoch 1/2\n",
            "85/85 [==============================] - 5s 20ms/step - loss: 0.0032 - val_loss: 6.1517e-04\n",
            "Epoch 2/2\n",
            "85/85 [==============================] - 1s 12ms/step - loss: 6.2802e-05 - val_loss: 5.5192e-04\n"
          ]
        }
      ],
      "source": [
        "# Build and Train GRU Model\n",
        "\n",
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "def build_and_train_gru(X_train, y_train, X_test, y_test, epochs=10, batch_size=1):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(50, return_sequences=True, input_shape=(time_step, 1)))\n",
        "    model.add(GRU(50, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
        "    return model, history\n",
        "\n",
        "gru_results = []\n",
        "for i, ((X_train, y_train), (X_test, y_test)) in enumerate(datasets_ts):\n",
        "    for params in hyperparams:\n",
        "        print(f\"Training GRU model with split {split_ratios[i]*100}-{(1-split_ratios[i])*100} and params {params}...\")\n",
        "        model, history = build_and_train_gru(X_train, y_train, X_test, y_test, epochs=params['epochs'], batch_size=params['batch_size'])\n",
        "        gru_results.append((model, history, f\"Split {split_ratios[i]*100}-{(1-split_ratios[i])*100}, Params {params}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25GjTHyKnP2d",
        "outputId": "794cdba9-ba64-4f78-9af8-e5750ac9fa75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 1s 5ms/step\n",
            "19/19 [==============================] - 0s 7ms/step\n",
            "85/85 [==============================] - 1s 6ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "85/85 [==============================] - 1s 5ms/step\n",
            "19/19 [==============================] - 0s 4ms/step\n",
            "85/85 [==============================] - 1s 4ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "\n",
            "LSTM Evaluation Results:\n",
            "Split 80.0-19.999999999999996, Params {'epochs': 2, 'batch_size': 1} - RMSE: 6.328367703854374, MAE: 5.394157474093845, R-squared: 0.9479250472918608\n",
            "Split 80.0-19.999999999999996, Params {'epochs': 2, 'batch_size': 32} - RMSE: 6.352955872953444, MAE: 5.046265966250056, R-squared: 0.8757179933813791\n",
            "\n",
            "GRU Evaluation Results:\n",
            "Split 80.0-19.999999999999996, Params {'epochs': 2, 'batch_size': 1} - RMSE: 3.381758599012753, MAE: 2.6379226045213726, R-squared: 0.9734378002598452\n",
            "Split 80.0-19.999999999999996, Params {'epochs': 2, 'batch_size': 32} - RMSE: 4.493041874240851, MAE: 3.7230616065189475, R-squared: 0.9449521940511639\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Models\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, scaler):\n",
        "    # Make predictions\n",
        "    train_predict = model.predict(X_train)\n",
        "    test_predict = model.predict(X_test)\n",
        "\n",
        "    # Invert predictions to original scale\n",
        "    train_predict = scaler.inverse_transform(np.concatenate((train_predict, np.zeros((train_predict.shape[0], scaler.scale_.shape[0] - 1))), axis=1))[:,0]\n",
        "    test_predict = scaler.inverse_transform(np.concatenate((test_predict, np.zeros((test_predict.shape[0], scaler.scale_.shape[0] - 1))), axis=1))[:,0]\n",
        "    y_train = scaler.inverse_transform(np.concatenate((y_train.reshape(-1, 1), np.zeros((y_train.shape[0], scaler.scale_.shape[0] - 1))), axis=1))[:,0]\n",
        "    y_test = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], scaler.scale_.shape[0] - 1))), axis=1))[:,0]\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, test_predict))\n",
        "    mae = mean_absolute_error(y_test, test_predict)\n",
        "    r2 = np.corrcoef(y_test, test_predict)[0, 1]**2\n",
        "\n",
        "    return rmse, mae, r2, y_test, test_predict\n",
        "\n",
        "# Evaluate LSTM models\n",
        "lstm_eval_results = []\n",
        "for model, history, desc in lstm_results:\n",
        "    for i, ((X_train, y_train), (X_test, y_test)) in enumerate(datasets_ts):\n",
        "        rmse, mae, r2, y_test_lstm, test_predict_lstm = evaluate_model(model, X_train, y_train, X_test, y_test, scaler)\n",
        "        lstm_eval_results.append((rmse, mae, r2, desc))\n",
        "\n",
        "# Evaluate GRU models\n",
        "gru_eval_results = []\n",
        "for model, history, desc in gru_results:\n",
        "    for i, ((X_train, y_train), (X_test, y_test)) in enumerate(datasets_ts):\n",
        "        rmse, mae, r2, y_test_gru, test_predict_gru = evaluate_model(model, X_train, y_train, X_test, y_test, scaler)\n",
        "        gru_eval_results.append((rmse, mae, r2, desc))\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"\\nLSTM Evaluation Results:\")\n",
        "for rmse, mae, r2, desc in lstm_eval_results:\n",
        "    print(f\"{desc} - RMSE: {rmse}, MAE: {mae}, R-squared: {r2}\")\n",
        "\n",
        "print(\"\\nGRU Evaluation Results:\")\n",
        "for rmse, mae, r2, desc in gru_eval_results:\n",
        "    print(f\"{desc} - RMSE: {rmse}, MAE: {mae}, R-squared: {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!google-chrome --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1_Ali6ExuGD",
        "outputId": "98399838-4511-4930-b74a-41ecc6cfffae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Chrome 127.0.6533.72 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "VAYbvKd3nP2e",
        "outputId": "b0710ccc-f67c-4748-c8c7-1c76957f133c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chromedriver-linux64\t\t\tgoogle-chrome-stable_current_amd64.deb.1\n",
            "chromedriver_linux64.zip\t\tgoogle-chrome-stable_current_amd64.deb.2\n",
            "google-chrome-stable_current_amd64.deb\tsample_data\n",
            "Archive:  chromedriver_linux64.zip\n",
            "  inflating: chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: chromedriver-linux64/THIRD_PARTY_NOTICES.chromedriver  \n",
            "  inflating: chromedriver-linux64/chromedriver  \n",
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/lib/chromium-browser/:/usr/bin/:/usr/lib/chromium-browser/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/:/usr/bin/\n",
            "Hit:1 https://dl.google.com/linux/chrome/deb stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Ign:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.23.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.26.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.7.4)\n",
            "Requirement already satisfied: typing_extensions~=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.9.0)\n",
            "Requirement already satisfied: websocket-client==1.8.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.7.4)\n",
            "Fetching news for AAPL...\n",
            "Headlines found: [\"Billionaire Warren Buffett Has Purchased $77 Billion of His Favorite Stock, Which Is More Than Double What He's Spent Buying Shares of Apple!\", 'Apple (AAPL) Stock Drops Despite Market Gains: Important Facts to Note', 'Apple stock is up 30% since Q2. Now what?', 'Apple Q3 Preview: Bears, Get Ready For Another iPhone Lesson (NASDAQ:AAPL)', 'Don’t Delay! 3 Stocks to Buy BEFORE Q2 Earnings.', 'Stock Market Game Plan For Investors After Biden Withdraws', 'Is Apple Inc (NASDAQ:AAPL) the Best Trump Trade According to Jim Cramer?', 'Apple (AAPL) Re-Emerged as a Top Performer in Q2', 'Apple Stock Buybacks And AI Are Just For Optics (NASDAQ:AAPL)', '3 Stocks That Are Melting Up. Is There Room to Run?', 'Don’t Bite Yet: Buy Apple Stock if AAPL Falls to This Level', 'Magnificent Seven Stocks To Buy And Watch', 'Apple Inc. (NASDAQ:AAPL) Stock Holdings Lifted by SWS Partners', \"Wall Street is Warming Up to Apple Stock Again, Here's Why\", 'Will Apple’s Q3 Results Get An AI Bump?', 'Apple Stock Hits Record High as Analysts Hike Price Targets on AI Optimism', 'Apple’s (NASDAQ:AAPL) Q3 Earnings Preview: Is This the End of Lackluster Quarters?', 'Apple Stock Quotes, Company News And Chart Analysis | Stock News & Stock Market Analysis', 'Valued Wealth Advisors LLC Grows Stock Holdings in Apple Inc. (NASDAQ:AAPL)', 'Will Apple Stock Split In 2024? July Edition', 'Is Trending Stock Apple Inc. (AAPL) a Buy Now?', 'AAPL Stock Analysis: Is Apple Really a Good Long-Term AI Bet?', 'AI Revolution: 3 Underdog Tech Stocks Powering the Future', 'Is Apple Stock A Buy After Tech Giant Hits $3.5 Trillion Market Cap?', 'Apple Stock Is More Expensive Than Nvidia (NASDAQ:AAPL)', 'BlueChip Wealth Advisors LLC Has $3.48 Million Stock Holdings in Apple Inc. (NASDAQ:AAPL)', \"Time to Buy Apple's (AAPL) Stock for Higher Highs?\", 'Morgan Stanley Doubles Down on Apple (AAPL) Stock With Top AI Call', 'Mac Sales Set to Rise 20.8%: Should You Buy Apple (AAPL) Stock?', 'Is Apple Inc. (NASDAQ:AAPL) The Most Undervalued AI Stock to Buy Now?', 'Microsoft Vs. Apple Vs. Google: Which AI Stock Is A Buy Ahead Of Earnings?', 'Apple Stock Hits Record High As iPhone Maker Gets Fresh Buy Rating', 'Apple (NASDAQ:AAPL) Stock Price Up 0.3% Following Analyst Upgrade', 'Apple Inc. (NASDAQ:AAPL) Stock Holdings Boosted by Yarger Wealth Strategies LLC', 'Is Apple Stock A Buy After Record Stock Buyback Announcement? July Edition', '10 Valuable Stocks That Could Be the Next Apple or Amazon', '3 Reasons to be Bullish on Apple Stock (NASDAQ:AAPL)', 'Apple Stock: Upcoming Q3 Earnings Report May Be Irrelevant (NASDAQ:AAPL)', 'Apple (AAPL) Stock Declined as Smartphone Demand Dropped', '2 Stocks That Can Help You to Get Richer in 2024', '‘Time to Go All In,’ Says Top Analyst About Apple Stock', 'Apple Inc. (NASDAQ:AAPL) Stock Holdings Cut by American Capital Advisory LLC', \"Apple's AI Vision May Finally Become Clear\", 'Should You Buy Apple Before This Key June 10 Event?', 'Apple Stock (NASDAQ:AAPL): It’s Not Just AI to Be Excited About', 'Possible Bearish Signals With Apple Insiders Disposing Stock', 'Apple Inc. (NASDAQ:AAPL) Stock Holdings Increased by FCG Investment Co', 'Apple (AAPL) Beats Stock Market Upswing: What Investors Need to Know', '3 Metaverse Stocks That Could Grow Your Wealth', 'Implied Volatility Surging for Apple (AAPL) Stock Options', 'Should You Buy Apple Stock Before June 10?', 'Shiny Apple? 3 Reasons to Buy and Hold AAPL Stock Forever.', \"Apple Stock Soars to New Peak. Here's Why I'm Doubling Down.\", 'Macroview Investment Management LLC Grows Stock Position in Apple Inc. (NASDAQ:AAPL)', 'Wooster Corthell Wealth Management Inc. Has $1.82 Million Stock Holdings in Apple Inc. (NASDAQ:AAPL)', 'Apple Stock (AAPL) Hits a New 52-Week High; Here’s Why', 'Blue-Chip Blunders: 7 Stocks to Sell as Management Missteps Mount', 'Apple Stock Forecast: Why The Best Is Yet To Come For AAPL', 'Apple Stock: Time To Sell (Downgrade) (NASDAQ:AAPL)', 'Apple Earnings Preview: Is AAPL Stock a Buy Ahead of the May 2 Report?', 'Private Wealth Management Group LLC Has $3.30 Million Stock Position in Apple Inc. (NASDAQ:AAPL)', 'Is Apple Inc (NASDAQ:AAPL) Aswath Damodaran’s Best AI Stock Pick?', 'Garrett Wealth Advisory Group LLC Reduces Stock Position in Apple Inc. (NASDAQ:AAPL)', 'First National Bank & Trust Co. of Newtown Decreases Stock Position in Apple Inc. (NASDAQ:AAPL)', 'Apple Stock Wins a New Street-High Price Target Due to the Big Gen AI Opportunity', 'Should You Buy Apple (AAPL) Stock Ahead of Q2 Earnings?', 'Sitrin Capital Management LLC Reduces Stock Position in Apple Inc. (NASDAQ:AAPL)', 'Forget the Metaverse! 7 Real-World Tech Stocks Poised for Breakout.', 'Field & Main Bank Has $13.74 Million Stock Holdings in Apple Inc. (NASDAQ:AAPL)', 'Apple Hits 52-Week High: Can AI Focus Drive AAPL Stock Higher?', 'Should You Buy Apple Stock Now or Wait for a Dip?', 'AAPL Shares Pop on $110 Billion Apple Stock Buyback Plans', \"Apple (AAPL) Stock Sinks As Market Gains: Here's Why\", 'Is Apple Stock a Buy Now?', 'Apple (NASDAQ:AAPL) stock performs better than its underlying earnings growth over last five years', 'Is Apple (AAPL) Stanley Druckenmiller’s Best AI Stock Pick?', 'Apple Addiction: 3 Fund Managers Doubling Down on AAPL Stock', 'Why Apple (AAPL) Stock Just Hit an All-Time High', 'Apple stock has best day since 2022 after earnings beat, $110 billion stock buyback', 'Apple Inc. (NASDAQ:AAPL) Stock Position Reduced by New Century Financial Group LLC', \"3 AI Stocks To Grab Now For 'Catch-Up' Gains\", 'Apple vs. Amazon Stock: Which Is the Better Buy?', 'Insight Inv LLC Has $5.04 Million Stock Position in Apple Inc. (NASDAQ:AAPL)', 'If You Can Only Buy One Magnificent 7 Stock in July, It Better Be One of These 3 Names', 'Horizon Bancorp Inc. IN Has $1.04 Million Stock Position in Apple Inc. (NASDAQ:AAPL)', 'Dear AAPL Stock Fans, Mark Your Calendars for May 7', '3 High-Flying Stocks That Show No Signs of Slowing Down', \"Apple Earnings Preview: Should You Buy AAPL Stock Ahead of Thursday's Q2 Report?\", 'AAPL Nears New All-Time High. Is Now the Best Time to Buy Apple Stock?', 'Apple Stock Out Of Favor, Hopes For Earnings Report Lift', 'Apple WDC 2024: Should You Buy AAPL Stock Before June 10?', 'Apple Stock: Great News From An AAPL Bear', 'Apple Inc. (NASDAQ:AAPL) Stock Holdings Decreased by Guardian Financial Partners LLC', 'Apple Stock Rises On AI Mac News. Shares Look To Retake Key Level.', 'AAPL Stock Outlook: Can the Apple $230 Stock Price Target Become Reality?', 'Apple Stock (NASDAQ:AAPL): 110 Billion Reasons to Buy after Buffett Sold', 'Apple (AAPL) Flirts With Support Levels After Worst Quarter in a Decade', 'Is Apple Inc. (NASDAQ:AAPL) Warren Buffett’s Favorite Dow Stock?', 'Who Owns Apple Stock (NASDAQ:AAPL)?']\n",
            "Fetching news for GOOGL...\n",
            "Headlines found: ['Stocks making the biggest moves after hours: Alphabet, Tesla, Visa and more', 'Google Earnings Beat. Shares Reverse Down On Margin Growth Outlook', 'Alphabet meets earnings expectations but misses on YouTube ad revenue', 'GOOGL Earnings: Alphabet Gains after Beating Q2 Estimates', 'Is Alphabet Inc. (NASDAQ:GOOG) the Best AI Stock to Buy Based on New AI ETF?', '4 stocks to watch on Tuesday: TSLA, GOOG/GOOGL and more', 'Prediction: 2 Artificial Intelligence Stocks That Could Be Worth More Than Nvidia 5 Years From Now', 'Google parent Alphabet beats quarterly revenue estimates', 'Google Backtracks On Third Party Cookie Policy, Sparks Gains In Ad Tech And Publisher Stocks', 'Alphabet Set To Report Strong Q2 Results With Increased Search Revenue: Analyst Bullish On Google Parent Flags 3 Things That Will Be On His Radar', 'Google Parent Alphabet Named To IBD 50: See Other Stocks New To The 50, IPO Leaders And Other Best Stocks Lists', 'Google Stock Could Rise On Q2 Cloud Growth Despite Busted Wiz Deal', 'Alphabet (GOOGL) Earnings: Can it Beat Expectations?', 'Alphabet Makes Big Digital Ad Decision Ahead Of Earnings. Is Google A Buy Or Sell?', 'Alphabet stock adds 2% as Google Search and Cloud fuel earnings beat', \"What's Going On With Google's Parent Alphabet Stock On Thursday?\", \"Alphabet earnings up next with Google parent's AI costs in focus\", 'Analysts revise Google stock price target ahead of earnings', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Acquired by Hudson Value Partners LLC', 'Alphabet’s Cloud Surge: Could GOOG Stock Soar to $300 per Share?', 'Alphabet (GOOGL) Stock: Buy, Sell or Hold Before Q2 Earnings?', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Sold by Jacobson & Schmitt Advisors LLC', 'Magnificent Seven Stocks To Buy And Watch', 'How Do You Recognize When A Market Rotates?', 'Cybersecurity Stocks To Watch As CrowdStrike Takes A Hit, Google-Wiz Deal Falls Apart', 'Futures: Tesla Earnings Miss, Musk Looms; Google Rises On Results', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Bought by Schneider Downs Wealth Management Advisors LP', 'OpenAI As The Next Google 20 Years After Its Landmark IPO', 'MSFT, AMZN, or GOOGL: Which Cloud Computing Player is the Best AI Stock?', 'Google CEO sells $4.11M in company stock (NASDAQ:GOOG)', 'TD Asset Management Inc Reduces Stock Position in Alphabet Inc. (NASDAQ:GOOGL)', 'Is Google A Buy As Of June 2024 Amid Wall Street Focus On Operating Margins, New CFO?', '2,379 Shares in Alphabet Inc. (NASDAQ:GOOGL) Acquired by Berkshire Money Management Inc.', 'Koshinski Asset Management Inc. Acquires 4,231 Shares of Alphabet Inc. (NASDAQ:GOOGL)', 'Tesla, Google, ServiceNow Highlight Latest Earnings Calendar', 'Analysts revamp Google parent stock price target into Q2 earnings', 'Google Stock Near Highs As AI Business Explodes', 'Is Amazon Stock A Buy As Analysts Project Strong Prime Day Sales?', 'Top Alphabet (Google) Shareholders', 'Alphabet Inc. (NASDAQ:GOOGL) Stock Holdings Lessened by OLD Second National Bank of Aurora', 'Is Google Stock A Buy After It Passes A $2 Trillion Valuation? July 2024 Edition', 'Choate Investment Advisors Trims Stock Holdings in Alphabet Inc. (NASDAQ:GOOGL)', 'HubSpot Shares Tumble As Alphabet Walks Away From Acquisition Talks', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Purchased by CarsonAllaria Wealth Management Ltd.', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Acquired by Foyston Gordon & Payne Inc', 'Time To Take Some Profits In Stock Market Leaders Google, Arista And Royal Caribbean', 'Is GOOGL Stock The Best Quality Stock to Buy Now?', \"What's Going On With Google Parent Alphabet Stock Monday?\", 'Microsoft Vs. Apple Vs. Google: Which AI Stock Is A Buy Ahead Of Earnings?', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Purchased by Horizon Investment Services LLC', 'Alphabet Inc. (NASDAQ:GOOGL) Stock Holdings Lessened by Capital City Trust Co. FL', 'Google stock likely to grind higher from here, rather than jumping: Jefferies', 'Alphabet Stock (NASDAQ:GOOGL) Q2 Earnings Preview: Another Chapter in Its Growth Story', \"Here's Why Alphabet (GOOGL) is a Must-Buy Stock Right Now\", 'Alphabet (GOOGL) Stock Falls Amid Market Uptick: What Investors Need to Know', 'GW Henssler & Associates Ltd. Decreases Stock Holdings in Alphabet Inc. (NASDAQ:GOOGL)', 'Alphabet Stock at All-Time Highs: Can GOOGL Overcome Gemini’s Shortcomings?', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Sold by Redwood Wealth Management Group LLC', 'Tesla, Google Set To Report Earnings As Megacap Tech Stocks Take A Hit', 'Google Stock Forecast and Price Prediction', \"Will Alphabet's Q2 Earnings Defy Bearish Trends?\", 'Alphabet Inc. (NASDAQ:GOOGL) Stock Holdings Trimmed by Metis Global Partners LLC', 'Mitsubishi UFJ Asset Management UK Ltd. Reduces Stock Position in Alphabet Inc. (NASDAQ:GOOGL)', 'Alphabet Buy Alert: Wall Street’s ‘Strong Buy’ on GOOG Stock Predicts Massive Gains', 'Alphabet (GOOGL) Stock Moves -0.6%: What You Should Know', 'WNY Asset Management LLC Purchases 435 Shares of Alphabet Inc. (NASDAQ:GOOGL)', 'NTV Asset Management LLC Purchases 940 Shares of Alphabet Inc. (NASDAQ:GOOGL)', 'I Keep Buying Alphabet Stock (NASDAQ:GOOGL), Post Q1 Rally; Here’s Why', 'TCI Wealth Advisors Inc. Buys 340 Shares of Alphabet Inc. (NASDAQ:GOOGL)', 'Google Stock: The AI Powerhouse You Can’t Ignore in 2024', 'Insight 2811 Inc. Has $435,000 Position in Alphabet Inc. (NASDAQ:GOOGL)', 'Google surges after buying back billions of dollars of its own stock', 'KCM Investment Advisors LLC Acquires 9,174 Shares of Alphabet Inc. (NASDAQ:GOOGL)', 'Atomi Financial Group Inc. Has $5.26 Million Stock Holdings in Alphabet Inc. (NASDAQ:GOOGL)', 'Stonebrook Private Inc. Purchases 1,879 Shares of Alphabet Inc. (NASDAQ:GOOGL)', 'Magnificent Seven Stocks: Apple Knocks Out Nvidia, Grabs This Crown From Microsoft', 'Smithfield Trust Co Acquires 368 Shares of Alphabet Inc. (NASDAQ:GOOGL)', \"Analysts Don't Expect Google, These Other Companies To Slow Their Profit Growth\", 'Oxbow Advisors LLC Trims Stock Holdings in Alphabet Inc. (NASDAQ:GOOGL)', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Purchased by Advisors Capital Management LLC', 'Google Stock Hits All-Time High With $2 Trillion Valuation In Sight', 'Google Stock Falls As Gemini Chatbot Generates Criticism', \"Google Stock Jumps On Earnings Beat, Dividend, New AI 'Narrative'\", 'Motive Wealth Advisors Has $868,000 Stock Holdings in Alphabet Inc. (NASDAQ:GOOGL)', 'Alphabet Inc. (NASDAQ:GOOGL) Shares Sold by Tweedy Browne Co LLC', 'Google I/O Event Expectations Run High Amid OpenAI, Microsoft Rivalry', 'Wall Street predicts Google stock price for next 12 months', 'Google Stock At Start Of \"New Secular Growth Cycle\" Due To AI Strength', 'Alphabet (GOOGL) Stock Drops Despite Market Gains: Important Facts to Note', 'Could Alphabet Stock Help You Retire a Millionaire?', 'Software Maker GitLab Seen Exploring Sale. Datadog, Google Among Suitors?', \"'Other Bets' Startup Mineral Bites The Dust In Google Cost Cutting Move\", 'Alphabet (GOOGL) Stock Moves -0.28%: What You Should Know', 'Sheets Smith Wealth Management Has $2.75 Million Stock Position in Alphabet Inc. (NASDAQ:GOOGL)', 'The Tech Trifecta: 3 Stocks With Unbeatable Combinations of Value, Growth and Momentum']\n",
            "Fetching news for MSFT...\n",
            "Headlines found: [\"Microsoft (MSFT) Laps the Stock Market: Here's Why\", 'MSFT, AMZN, or GOOGL: Which Cloud Computing Player is the Best AI Stock?', 'Microsoft Stock Could Be Cooling; Option Trade Profits From A Pause', 'Microsoft Stock Has Further Room To Run, Says Analyst, As Software Giant Remains On Track To Hit $200B Cloud Revenue In 2 Years', 'Microsoft Q4 Preview: Google Is Real AI Competition Now (Rating Downgrade) (NASDAQ:MSFT)', \"Microsoft Stock Is Great, But I'm Not Buying Because of This Huge Red Flag\", 'Is Microsoft Corp (NASDAQ:MSFT) the Best AI Stock to Buy Based on New AI ETF?', 'Microsoft (NASDAQ:MSFT) Stock Price Up 1.5%', 'Should You Buy, Sell or Hold Microsoft (MSFT) Before Q4 Earnings?', 'Do Hedge Funds Think That Microsoft Corporation (MSFT) Will Skyrocket Soon?', 'Magnificent Seven Stocks To Buy And Watch', 'MSFT Stock Quote Price and Forecast', 'Microsoft Stock Price in 5 Years: Can MSFT Shares Ride Out CrowdStrike Outage, Antitrust Headwinds?', 'Why Microsoft Stock Is a Safe Bet for the Second Half of 2024', 'Microsoft (MSFT) Price Prediction and Forecast 2025-2030', 'Watch These Microsoft Stock Price Levels After Major Cloud Services Outage', \"Is Microsoft Corporation's (NASDAQ:MSFT) Stock's Recent Performance A Reflection Of Its Financial Health?\", 'Is Microsoft Corp (NASDAQ:MSFT) the Best AI Stock to Buy Based on New AI ETF?', 'Analysts revise Microsoft stock price target', 'MSFT, AMZN, or GOOGL: Which Cloud Computing Player is the Best AI Stock?', \"Is MSFT Stock A Buy Now? Here's The Chart Update\", 'MSFT Stock Falls as CrowdStrike Outage Knocks Out Microsoft Systems', 'Here’s why Microsoft stock is about to crash', 'Microsoft (MSFT) Stock Quotes, Company News And Chart Analysis', 'Bank of America Just Raised Its Price Target on Microsoft (MSFT) Stock', 'Microsoft (MSFT) Stock Dips While Market Gains: Key Facts', 'Can Microsoft Stock Reach $1,000?', 'Should You Buy Mag 7 Weakness?', 'Beam Wealth Advisors Inc. Decreases Stake in Microsoft Co. (NASDAQ:MSFT)', 'Stock-Split Watch: Is Microsoft Next?', 'Crowdstrike Outage Has Citi Analyst Concerned about Microsoft’s (NASDAQ:MSFT) Security', 'Analyst: Microsoft Corp (NASDAQ:MSFT) in ‘Great Shape’ With Its ‘Copilot Strategy’', 'Microsoft Stock (NASDAQ: MSFT) Q4 Earnings Preview: Poised for a Strong Beat', 'Microsoft Vs. Apple Vs. Google: Which AI Stock Is A Buy Ahead Of Earnings?', 'MSFT Stock: Is Microsoft Parting Ways with Being Woke?', 'Microsoft Stock Pullback Posing Potential Entry Point', 'MSFT: Why Valuations And Volatility Ultimately Matter In Microsoft And Other AI Fueled Stocks', 'Global Outage Chaos: Microsoft (NASDAQ:MSFT) Cloud Glitch Cripples Services Worldwide', 'Microsoft (MSFT) finds key support. - Microsoft (NASDAQ:MSFT)', \"Microsoft, Palantir, others expected to be 'standouts' during earnings: Wedbush\", 'Microsoft To Rally Around 10%? Here Are 10 Top Analyst Forecasts For Tuesday', 'Microsoft Co. (NASDAQ:MSFT) is Argent Capital Management LLC’s Largest Position', 'Retirement Systems of Alabama Has $1.22 Billion Holdings in Microsoft Co. (NASDAQ:MSFT)', '5 Things to Know Before the Stock Market Opens', 'Microsoft Co. (NASDAQ:MSFT) Shares Sold by Meritage Portfolio Management', 'Field & Main Bank Reduces Stock Position in Microsoft Co. (NASDAQ:MSFT)', 'Diversified Investment Strategies LLC Sells 154 Shares of Microsoft Co. (NASDAQ:MSFT)', 'Microsoft Co. (NASDAQ:MSFT) Given Consensus Rating of \"Moderate Buy\" by Brokerages', 'Summit Global Investments Cuts Stock Position in Microsoft Co. (NASDAQ:MSFT)', 'Stocks to watch this week: Tesla, Microsoft, Alphabet and Amazon', 'RWA Wealth Partners LLC Sells 5,303 Shares of Microsoft Co. (NASDAQ:MSFT)', 'Sierra Capital LLC Has $4.96 Million Position in Microsoft Co. (NASDAQ:MSFT)', 'Castle Wealth Management LLC Cuts Position in Microsoft Co. (NASDAQ:MSFT)', 'CRWD Stock Plunges as CrowdStrike Triggers Massive Global Outage. What to Know.', 'Silicon Valley Capital Partners Increases Position in Microsoft Co. (NASDAQ:MSFT)', 'What Makes Microsoft Corporation (MSFT) a Great Investment?', 'US Bancorp DE Boosts Stock Position in The AES Co. (NYSE:AES)', 'Forthright Family Wealth Advisory LLC Purchases 177 Shares of Microsoft Co. (NASDAQ:MSFT)', 'Should You Buy Amazon Stock Instead of Microsoft Stock?', 'Microsoft’s Secret Weapon: Why MSFT Stock Could Soar to $550', 'Monte Financial Group LLC Has $3.72 Million Stock Holdings in Microsoft Co. (NASDAQ:MSFT)', 'Microsoft Stock: The Value Play Set to Double Again in 21 Months', 'Should Investors Buy Microsoft Stock Before July 30?', 'Is Microsoft Corporation (NASDAQ:MSFT) the Best Mega-Cap Dow Stock to Buy Now?', 'Microsoft’s AI Gambit: Why MSFT Stock Could Soar Even Higher', 'Naples Global Advisors LLC Lowers Position in Microsoft Co. (NASDAQ:MSFT)', 'S&P 500: Magnificent Seven Stocks Suffer Their Worst Market Cap Loss In Two Years', 'Microsoft (MSFT) Stock Forecast and Price Prediction', \"Is Microsoft Corporation's (NASDAQ:MSFT) Latest Stock Performance A Reflection Of Its Financial Health?\", 'Microsoft: Stock Rally Is At Risk (NASDAQ:MSFT)', '3 Reliable Blue-Chip Stocks to Buy, Hold and Never Let Go', 'Lederer & Associates Investment Counsel CA Has $11.54 Million Stake in Microsoft Co. (NASDAQ:MSFT)', 'Microsoft Co. (NASDAQ:MSFT) Shares Sold by Benjamin F. Edwards & Company Inc.', 'MSFT Alert: Buy Microsoft Stock Before the Next Move Higher', 'Objective long/short (MSFT) Report', 'CrowdStrike stock slips 15% on global outage; rival cyber stocks head higher (NASDAQ:CRWD)', 'Microsoft (NASDAQ:MSFT) and CrowdStrike (NASDAQ:CRWD) Tumble amid IT Global Outage', 'Microsoft Stock Analysis: MSFT Is Your Ticket to $500 Per Share in 2024', 'CareDx, Inc (NASDAQ:CDNA) Stock Position Raised by Allspring Global Investments Holdings LLC', 'Microsoft Stock Analysis: Why You Should Buy the MSFT Dip', 'Microsoft Co. (NASDAQ:MSFT) Shares Bought by RBA Wealth Management LLC', 'Microsoft (MSFT) Stock Moves -0.27%: What You Should Know', 'Could Microsoft Stock Help You Retire a Millionaire?', 'Concord Wealth Partners Buys 6,106 Shares of Microsoft Co. (NASDAQ:MSFT)', 'US Bancorp DE Cuts Stock Holdings in Citizens Financial Group, Inc. (NYSE:CFG)', 'Microsoft Stock Outlook: 2 Key Reasons to Buy and Hold MSFT Forever', 'The 5 Most Important Stocks to Watch During Q2 Earnings Season', \"What's Going On With Microsoft Stock Today?\", \"What Is Microsoft Corporation's (NASDAQ:MSFT) Share Price Doing?\", 'MICROSOFT CORPORATION (MSFT)', 'Microsoft Stock (NASDAQ:MSFT) Can Still Rise Despite Sitting at the Top', 'Allspring Global Investments Holdings LLC Sells 6,647 Shares of U.S. Silica Holdings, Inc. (NYSE:SLCA)', 'Analyst Thinks Microsoft Corp (NASDAQ:MSFT) Has More Upside Due to AI', 'Analysts Think Microsoft Corp (NASDAQ:MSFT) is Still The Best AI Stock — Here’s Why', 'Microsoft (MSFT) Stock Moves -0.04%: What You Should Know', 'Microsoft’s AI Edge: Why MSFT Stock Is Poised to Outperform Apple and Nvidia', 'Microsoft Stock Outlook: Is MSFT a Millionaire-Maker AI Play to Make?', 'MSFT Stock Forecast: 3 Explosive Reasons to Own Microsoft Now', 'Is Microsoft Corporation (NASDAQ:MSFT) the Best Quality Dividend Stock to Buy According to Reddit?']\n"
          ]
        }
      ],
      "source": [
        "# You will need to install chrome driver for this section to work correctly\n",
        "\n",
        "# Ensure the uploaded file is listed\n",
        "!ls\n",
        "\n",
        "# Unzip the uploaded ChromeDriver file with overwrite option\n",
        "!unzip -o chromedriver_linux64.zip\n",
        "\n",
        "# Move the chromedriver to /usr/bin/ and set permissions\n",
        "!chmod +x chromedriver-linux64/chromedriver\n",
        "!mv chromedriver-linux64/chromedriver /usr/bin/chromedriver\n",
        "\n",
        "# Set up environment variables\n",
        "import os\n",
        "os.environ['PATH'] += ':/usr/bin/'\n",
        "\n",
        "# Print the PATH variable to ensure chromedriver is in the PATH\n",
        "print(os.environ['PATH'])\n",
        "\n",
        "\n",
        "# Install the necessary packages\n",
        "!apt-get update\n",
        "!apt-get install -y wget unzip\n",
        "!pip install selenium\n",
        "!pip install vaderSentiment\n",
        "\n",
        "\n",
        "# Collect News Data\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Define the path to chromedriver\n",
        "chromedriver_path = '/usr/bin/chromedriver'\n",
        "\n",
        "def scrape_news(stock):\n",
        "    driver = webdriver.Chrome(service=Service(chromedriver_path), options=chrome_options)\n",
        "    url = f'https://news.google.com/search?q={stock}%20stock&hl=en-US&gl=US&ceid=US%3Aen'\n",
        "    driver.get(url)\n",
        "\n",
        "    # Allow time for the page to load and find headlines\n",
        "    try:\n",
        "        print(f\"Fetching news for {stock}...\")\n",
        "        article_elements = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'article.IFHyqb'))\n",
        "        )\n",
        "\n",
        "        headlines = []\n",
        "        for article in article_elements:\n",
        "            headline_element = article.find_element(By.CSS_SELECTOR, 'a.JtKRv')\n",
        "            if headline_element:\n",
        "                headlines.append(headline_element.text)\n",
        "\n",
        "        print(f\"Headlines found: {headlines}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        headlines = []\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "    return headlines\n",
        "\n",
        "# Scrape news for each stock\n",
        "news_aapl = scrape_news('AAPL')\n",
        "news_googl = scrape_news('GOOGL')\n",
        "news_msft = scrape_news('MSFT')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhRXtvxJnP2e"
      },
      "outputs": [],
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define function to calculate sentiment scores\n",
        "def get_sentiment_scores(headlines):\n",
        "    scores = [analyzer.polarity_scores(headline)['compound'] for headline in headlines]\n",
        "    return scores\n",
        "\n",
        "# Get sentiment scores for each stock\n",
        "sentiment_aapl = get_sentiment_scores(news_aapl)\n",
        "sentiment_googl = get_sentiment_scores(news_googl)\n",
        "sentiment_msft = get_sentiment_scores(news_msft)\n",
        "\n",
        "# Ensure the lengths of sentiment arrays are the same\n",
        "min_length = min(len(sentiment_aapl), len(sentiment_googl), len(sentiment_msft))\n",
        "sentiment_aapl = sentiment_aapl[:min_length]\n",
        "sentiment_googl = sentiment_googl[:min_length]\n",
        "sentiment_msft = sentiment_msft[:min_length]\n",
        "\n",
        "# Calculate average sentiment\n",
        "avg_sentiment_aapl = sum(sentiment_aapl) / len(sentiment_aapl)\n",
        "avg_sentiment_googl = sum(sentiment_googl) / len(sentiment_googl)\n",
        "avg_sentiment_msft = sum(sentiment_msft) / len(sentiment_msft)\n",
        "\n",
        "print(f'Average Sentiment - AAPL: {avg_sentiment_aapl}, GOOGL: {avg_sentiment_googl}, MSFT: {avg_sentiment_msft}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0_zvI03nP2e"
      },
      "outputs": [],
      "source": [
        "# Visualizations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot LSTM predictions vs actual values\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(y_test_lstm, label='Actual')\n",
        "plt.plot(test_predict_lstm, label='Predicted')\n",
        "plt.title('Stock Price Prediction using LSTM')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot GRU predictions vs actual values\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(y_test_gru, label='Actual')\n",
        "plt.plot(test_predict_gru, label='Predicted')\n",
        "plt.title('Stock Price Prediction using GRU')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3E_xJ5inP2e"
      },
      "outputs": [],
      "source": [
        "# Plot sentiment scores for each stock\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.bar(['AAPL', 'GOOGL', 'MSFT'], [avg_sentiment_aapl, avg_sentiment_googl, avg_sentiment_msft], color=['blue', 'orange', 'green'])\n",
        "plt.title('Average Sentiment Scores')\n",
        "plt.xlabel('Stock')\n",
        "plt.ylabel('Average Sentiment Score')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddgiGHzenP2e"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss for LSTM model\n",
        "for model, history, desc in lstm_results:\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Training and Validation Loss - LSTM Model - {desc}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot training and validation loss for GRU model\n",
        "for model, history, desc in gru_results:\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Training and Validation Loss - GRU Model - {desc}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOrGlYmgnP2e"
      },
      "outputs": [],
      "source": [
        "# Integrate Sentiment Data with Stock Prices\n",
        "\n",
        "# Sample stock price data\n",
        "dates = pd.date_range(start='2024-01-01', periods=min_length, freq='D')\n",
        "data = pd.DataFrame(index=dates)\n",
        "data['AAPL'] = np.random.rand(min_length)  # Replace with actual stock price data\n",
        "data['GOOGL'] = np.random.rand(min_length)  # Replace with actual stock price data\n",
        "data['MSFT'] = np.random.rand(min_length)  # Replace with actual stock price data\n",
        "\n",
        "# Convert sentiment scores to DataFrame\n",
        "sentiment_df = pd.DataFrame({\n",
        "    'AAPL_Sentiment': sentiment_aapl,\n",
        "    'GOOGL_Sentiment': sentiment_googl,\n",
        "    'MSFT_Sentiment': sentiment_msft\n",
        "}, index=dates)  # Ensure indices match\n",
        "\n",
        "# Combine sentiment scores with stock price data\n",
        "data = data.join(sentiment_df, how='inner')\n",
        "\n",
        "# Fill missing values created by aligning the sentiment data with the stock price data\n",
        "data = data.bfill()\n",
        "\n",
        "# Scale the updated data\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Function to create dataset for LSTM\n",
        "def create_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-time_step-1):\n",
        "        a = dataset[i:(i+time_step), :]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + time_step, 0])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# Function to split data into training and testing sets\n",
        "def split_data(dataset, ratio=0.8):\n",
        "    train_size = int(len(dataset) * ratio)\n",
        "    test_size = len(dataset) - train_size\n",
        "    train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
        "    return train, test\n",
        "\n",
        "# Prepare data for LSTM with sentiment\n",
        "time_step = 10\n",
        "split_ratios = [0.8]\n",
        "datasets = [split_data(data_scaled, ratio) for ratio in split_ratios]\n",
        "datasets_ts = [(create_dataset(train, time_step), create_dataset(test, time_step)) for train, test in datasets]\n",
        "\n",
        "for i, ((X_train, y_train), (X_test, y_test)) in enumerate(datasets_ts):\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
        "    print(f\"X_train shape for split {split_ratios[i]*100}-{(1-split_ratios[i])*100} with sentiment: {X_train.shape}\")\n",
        "    print(f\"X_test shape for split {split_ratios[i]*100}-{(1-split_ratios[i])*100} with sentiment: {X_test.shape}\")\n",
        "\n",
        "# Define the LSTM model\n",
        "def build_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "# Define the GRU model\n",
        "def build_gru_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(50, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(GRU(50))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, epochs=2, batch_size=1):\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "    train_predict = model.predict(X_train)\n",
        "    test_predict = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, test_predict))\n",
        "    mae = mean_absolute_error(y_test, test_predict)\n",
        "    r2 = r2_score(y_test, test_predict)\n",
        "    return rmse, mae, r2\n",
        "\n",
        "# Train and evaluate models\n",
        "rmse_lstm, mae_lstm, r2_lstm = train_and_evaluate_model(build_lstm_model((time_step, data_scaled.shape[1])),\n",
        "                                                        X_train, y_train, X_test, y_test, epochs=2, batch_size=1)\n",
        "rmse_gru, mae_gru, r2_gru = train_and_evaluate_model(build_gru_model((time_step, data_scaled.shape[1])),\n",
        "                                                     X_train, y_train, X_test, y_test, epochs=2, batch_size=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2MGVN94nP2e"
      },
      "outputs": [],
      "source": [
        "# Comparison of model performance with sentiment integration\n",
        "models = ['LSTM', 'GRU']\n",
        "rmse_scores = [rmse_lstm, rmse_gru]\n",
        "mae_scores = [mae_lstm, mae_gru]\n",
        "r2_scores = [r2_lstm, r2_gru]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.bar(x, rmse_scores, color=['blue', 'orange'])\n",
        "plt.xticks(x, models)\n",
        "plt.title('RMSE Comparison')\n",
        "plt.ylabel('RMSE')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.bar(x, mae_scores, color=['blue', 'orange'])\n",
        "plt.xticks(x, models)\n",
        "plt.title('MAE Comparison')\n",
        "plt.ylabel('MAE')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(x, r2_scores, color=['blue', 'orange'])\n",
        "plt.xticks(x, models)\n",
        "plt.title('R-squared Comparison')\n",
        "plt.ylabel('R-squared')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHV_g32KnP2e"
      },
      "outputs": [],
      "source": [
        "# Function to process data for a specific stock\n",
        "def process_stock_data(stock_data):\n",
        "    stock_data = stock_data.rolling(window=50).mean()\n",
        "    stock_data = stock_data.bfill()\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    data_scaled = scaler.fit_transform(stock_data.values.reshape(-1, 1))\n",
        "    return stock_data, data_scaled, scaler\n",
        "\n",
        "# Function to create dataset for LSTM\n",
        "def create_dataset(dataset, time_step=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - time_step - 1):\n",
        "        X.append(dataset[i:(i + time_step), 0])\n",
        "        Y.append(dataset[i + time_step, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "# Function to split data into training and testing sets\n",
        "def split_data(data, split_ratio=0.8):\n",
        "    train_size = int(len(data) * split_ratio)\n",
        "    train_data, test_data = data[:train_size], data[train_size:]\n",
        "    return train_data, test_data\n",
        "\n",
        "# Function to build and train LSTM model\n",
        "def build_and_train_lstm(X_train, y_train, X_test, y_test, epochs=2, batch_size=1, time_step=10):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
        "    return model, history\n",
        "\n",
        "# Function to build and train GRU model\n",
        "def build_and_train_gru(X_train, y_train, X_test, y_test, epochs=2, batch_size=1, time_step=10):\n",
        "    model = Sequential()\n",
        "    model.add(GRU(50, return_sequences=True, input_shape=(time_step, 1)))\n",
        "    model.add(GRU(50, return_sequences=False))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
        "    return model, history\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, X_test, y_test, scaler):\n",
        "    test_predict = model.predict(X_test)\n",
        "    test_predict = scaler.inverse_transform(np.concatenate((test_predict, np.zeros((test_predict.shape[0], 1))), axis=1))[:, 0]\n",
        "    y_test = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((y_test.shape[0], 1))), axis=1))[:, 0]\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, test_predict))\n",
        "    mae = mean_absolute_error(y_test, test_predict)\n",
        "    r2 = np.corrcoef(y_test, test_predict)[0, 1] ** 2\n",
        "    return rmse, mae, r2, y_test, test_predict\n",
        "\n",
        "# Function to plot projected stock prices\n",
        "def plot_projected_prices(dates, y_test, test_predict, title):\n",
        "    print(f\"Plotting: {title}\")\n",
        "    print(f\"Dates: {dates}\")\n",
        "    print(f\"y_test: {y_test}\")\n",
        "    print(f\"test_predict: {test_predict}\")\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.plot(dates, y_test, label='Actual Stock Price', color='blue')\n",
        "    plt.plot(dates, test_predict, label='Predicted Stock Price', color='orange')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Stock Price')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlHuATPynP2f"
      },
      "outputs": [],
      "source": [
        "# Model Training and Evaluation for Each Stock\n",
        "time_step = 10  # Further reduced time step to ensure there is enough data\n",
        "split_ratios = [0.8]  # List of split ratios\n",
        "hyperparams = [{'epochs': 2, 'batch_size': 1}, {'epochs': 2, 'batch_size': 32}]\n",
        "stocks = ['AAPL', 'GOOGL', 'MSFT']\n",
        "\n",
        "for stock in stocks:\n",
        "    stock_data = data[stock]  # Get specific stock data as a Series\n",
        "    stock_data, data_scaled, scaler = process_stock_data(stock_data)\n",
        "    print(f\"Data length for {stock} after scaling: {len(data_scaled)}\")\n",
        "    if len(data_scaled) <= time_step:\n",
        "        print(f\"Not enough data for stock {stock} with time_step {time_step}\")\n",
        "        continue\n",
        "\n",
        "    for split_ratio in split_ratios:\n",
        "        train_data, test_data = split_data(data_scaled, split_ratio)\n",
        "        X_train, y_train = create_dataset(train_data, time_step)\n",
        "        X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "        # Check if there is enough data to reshape\n",
        "        if len(X_train) == 0 or len(X_test) == 0:\n",
        "            print(f\"Not enough data for stock {stock} with time_step {time_step}\")\n",
        "            continue\n",
        "\n",
        "        X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "        # Train and evaluate LSTM models\n",
        "        for params in hyperparams:\n",
        "            model_lstm, history_lstm = build_and_train_lstm(X_train, y_train, X_test, y_test, epochs=params['epochs'], batch_size=params['batch_size'], time_step=time_step)\n",
        "            rmse_lstm, mae_lstm, r2_lstm, y_test_lstm, test_predict_lstm = evaluate_model(model_lstm, X_test, y_test, scaler)\n",
        "            start_date = pd.to_datetime('2024-01-01')\n",
        "            dates = pd.date_range(start=start_date, periods=len(y_test_lstm), freq='D')\n",
        "            plot_projected_prices(dates, y_test_lstm, test_predict_lstm, f'Projected Stock Prices using LSTM for {stock} with split ratio {split_ratio}')\n",
        "\n",
        "        # Train and evaluate GRU models\n",
        "        for params in hyperparams:\n",
        "            model_gru, history_gru = build_and_train_gru(X_train, y_train, X_test, y_test, epochs=params['epochs'], batch_size=params['batch_size'], time_step=time_step)\n",
        "            rmse_gru, mae_gru, r2_gru, y_test_gru, test_predict_gru = evaluate_model(model_gru, X_test, y_test, scaler)\n",
        "            start_date = pd.to_datetime('2024-01-01')\n",
        "            dates = pd.date_range(start=start_date, periods=len(y_test_gru), freq='D')\n",
        "            plot_projected_prices(dates, y_test_gru, test_predict_gru, f'Projected Stock Prices using GRU for {stock} with split ratio {split_ratio}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}